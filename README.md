# Vision.ai
Vision.ai helps visually impaired individuals by generating real-time image captions and converting them into speech. It uses CNNs for feature extraction, LSTMs for captioning, GANs for refinement, ML for optimization, and NLP for accuracy. With AI-driven assistance, Vision.ai enables users to better understand their surroundings instantly.

# Vision.ai

**Vision.ai** is an AI-powered assistive technology designed for visually impaired individuals. It generates real-time captions for uploaded images and converts them into speech, enabling users to understand their surroundings through AI.

## üöÄ Features

- **Real-Time Image Captioning**: Uses CNN, LSTM, and GAN models for accurate caption generation.
- **Speech Output**: Converts text captions into speech for easy understanding.
- **Machine Learning & NLP**: Enhances caption quality, ensuring fluency and grammatical correctness.
- **User-Friendly Interface**: Simple image upload system with an accessible UI.

## üõ†Ô∏è Tech Stack

- **Deep Learning**: CNN (Feature Extraction), LSTM (Captioning), GAN (Refinement)
- **Machine Learning**: Model optimization and fine-tuning
- **Natural Language Processing (NLP)**: Ensuring grammatically correct and contextually accurate captions
- **Text-to-Speech (TTS)**: Uses `pyttsx3` for speech synthesis
- **Frontend**: HTML, CSS, JavaScript
- **Backend**: Python (Flask/FastAPI)
- **Libraries**: PyTorch, OpenCV, NumPy, scikit-learn, NLTK, pyttsx3

## üì¶ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/nikhilitz/Vision.ai.git
   cd Vision.ai
   
   
